{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Install Dependencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install nibabel\n",
      "!pip install nilearn\n",
      "!pip install pydicom\n",
      "!pip install tensorboardX\n",
      "!pip install tqdm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: nibabel in /opt/anaconda3/lib/python3.7/site-packages (2.4.0)\r\n",
        "Requirement already satisfied: numpy>=1.8 in /opt/anaconda3/lib/python3.7/site-packages (from nibabel) (1.15.4)\r\n",
        "Requirement already satisfied: six>=1.3 in /opt/anaconda3/lib/python3.7/site-packages (from nibabel) (1.12.0)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: nilearn in /opt/anaconda3/lib/python3.7/site-packages (0.5.2)\r\n",
        "Requirement already satisfied: nibabel>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from nilearn) (2.4.0)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: numpy>=1.8 in /opt/anaconda3/lib/python3.7/site-packages (from nibabel>=2.0.2->nilearn) (1.15.4)\r\n",
        "Requirement already satisfied: six>=1.3 in /opt/anaconda3/lib/python3.7/site-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: pydicom in /opt/anaconda3/lib/python3.7/site-packages (1.2.2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: tensorboardX in /opt/anaconda3/lib/python3.7/site-packages (1.6)\r\n",
        "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.15.4)\r\n",
        "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.12.0)\r\n",
        "Requirement already satisfied: protobuf>=3.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboardX) (3.7.0)\r\n",
        "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.2.0->tensorboardX) (40.6.3)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (4.31.1)\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#General imports\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import pydicom\n",
      "# from pydicom.data import get_testdata_files\n",
      "# from pydicom.filereader import read_dicomdir\n",
      "from subprocess import call\n",
      "import sys\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "#Pytorch imports\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "from torch.optim import lr_scheduler\n",
      "\n",
      "#Local imports\n",
      "from utils import Logger,load_old_model\n",
      "from train import train_epoch\n",
      "from validation import val_epoch\n",
      "from nvnet import MiniNvNet, NvNet\n",
      "from metrics import CombinedLoss, SoftDiceLoss\n",
      "from dataset import BratsDataset, StanfordDataset\n",
      "\n",
      "# for auto-reloading external modules\n",
      "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "GPU Parameters/Status"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\"\n",
      "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
      "\n",
      "torch.cuda.empty_cache()\n",
      "print('__Python VERSION:', sys.version)\n",
      "print('__pyTorch VERSION:', torch.__version__)\n",
      "print('__CUDA VERSION')\n",
      "\n",
      "# call([\"nvcc\", \"--version\"]) does not work\n",
      "! nvcc --version\n",
      "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
      "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
      "print('__Devices')\n",
      "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
      "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
      "\n",
      "print ('Available devices ', torch.cuda.device_count())\n",
      "print ('Current cuda device ', torch.cuda.current_device())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__Python VERSION: 3.7.1 (default, Dec 14 2018, 19:28:38) \n",
        "[GCC 7.3.0]\n",
        "__pyTorch VERSION: 1.0.1.post2\n",
        "__CUDA VERSION\n",
        "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
        "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
        "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
        "Cuda compilation tools, release 10.0, V10.0.130\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__CUDNN VERSION: 7402\n",
        "__Number CUDA Devices: 2\n",
        "__Devices\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Active CUDA Device: GPU 0\n",
        "Available devices  2\n",
        "Current cuda device  0\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Config"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = dict()\n",
      "config[\"cuda_devices\"] = True\n",
      "# config[\"labels\"] = (1, 2, 4)\n",
      "config[\"labels\"] = (1,) # change label to train\n",
      "config[\"model_file\"] = os.path.abspath(\"single_label_{}_dice.h5\".format(config[\"labels\"][0]))\n",
      "config[\"initial_learning_rate\"] = 1e-5\n",
      "config[\"batch_size\"] = 2\n",
      "config[\"validation_batch_size\"] = 2\n",
      "config[\"image_shape\"] = (128, 128, 128)\n",
      "# config[\"image_shape\"] = (160, 512, 512)\n",
      "# config[\"image_shape\"] = (160, 256, 256)\n",
      "config[\"activation\"] = \"relu\"\n",
      "config[\"normalizaiton\"] = \"group_normalization\"\n",
      "config[\"mode\"] = \"trilinear\"\n",
      "config[\"n_labels\"] = len(config[\"labels\"])\n",
      "#config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
      "config[\"all_modalities\"] = [\"bilat\"]#[\"t1\", \"sag\"]\n",
      "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
      "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
      "config[\"input_shape\"] = tuple([config[\"batch_size\"]] + [config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
      "config[\"loss_k1_weight\"] = 0.1\n",
      "config[\"loss_k2_weight\"] = 0.1\n",
      "config[\"random_offset\"] = True # Boolean. Augments the data by randomly move an axis during generating a data\n",
      "config[\"random_flip\"] = True  # Boolean. Augments the data by randomly flipping an axis during generating a data\n",
      "# config[\"permute\"] = True  # data shape must be a cube. Augments the data by permuting in various directions\n",
      "config[\"result_path\"] = \"./checkpoint_models/\"\n",
      "config[\"data_file\"] = os.path.abspath(\"isensee_mixed_brats_data.h5\")\n",
      "# config[\"training_file\"] = os.path.abspath(\"isensee_mixed_training_ids.pkl\")\n",
      "# config[\"validation_file\"] = os.path.abspath(\"isensee_mixed_validation_ids.pkl\")\n",
      "# config[\"test_file\"] = os.path.abspath(\"isensee_mixed_validation_ids.pkl\")\n",
      "config[\"training_dir\"] = \"data/preprocessed/train\"\n",
      "config[\"validation_dir\"] = \"data/preprocessed/val\"\n",
      "config[\"test_dir\"] = \"data/preprocessed/test\"\n",
      "config[\"saved_model_file\"] = None#\"checkpoint_models/single_label_1_dice/best_model_file.pth\" #None\n",
      "config[\"overwrite\"] = False  # If True, will create new files. If False, will use previously written files.\n",
      "config[\"L2_norm\"] = 1e-5\n",
      "config[\"patience\"] = 2\n",
      "config[\"lr_decay\"] = 0.7\n",
      "config[\"epochs\"] = 300\n",
      "config[\"checkpoint\"] = True  # Boolean. If True, will save the best model as checkpoint.\n",
      "config[\"label_containing\"] = True  # Boolean. If True, will generate label with overlapping.\n",
      "config[\"VAE_enable\"] = True  # Boolean. If True, will enable the VAE module."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Detect GPU availability"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "USE_GPU = True\n",
      "\n",
      "dtype = torch.float32 # we will be using float throughout this tutorial\n",
      "\n",
      "if USE_GPU and torch.cuda.is_available():\n",
      "    device = torch.device('cuda')\n",
      "    config[\"cuda_devices\"] = True\n",
      "else:\n",
      "    device = torch.device('cpu')\n",
      "    config[\"cuda_devices\"] = False\n",
      "\n",
      "# Constant to control how frequently we print train loss\n",
      "print_every = 100\n",
      "\n",
      "print('using device:', device)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using device: cuda\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Definition for train cycle"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    # init or load model\n",
      "    print(\"init model with input shape\",config[\"input_shape\"])\n",
      "    model = NvNet(config=config)\n",
      "    #model = MiniNvNet(config=config)\n",
      "    parameters = model.parameters()\n",
      "    optimizer = optim.Adam(parameters, \n",
      "                           lr=config[\"initial_learning_rate\"],\n",
      "                           weight_decay = config[\"L2_norm\"])\n",
      "    start_epoch = 1\n",
      "    if config[\"VAE_enable\"]:\n",
      "        loss_function = CombinedLoss(k1=config[\"loss_k1_weight\"], k2=config[\"loss_k2_weight\"])\n",
      "    else:\n",
      "        loss_function = SoftDiceLoss()\n",
      "    # data_generator\n",
      "    print(\"data generating\")\n",
      "    training_data = StanfordDataset(phase=\"train\", config=config)\n",
      "    validation_data = StanfordDataset(phase=\"validate\", config=config)\n",
      "\n",
      "    train_logger = Logger(model_name=config[\"model_file\"],header=['epoch', 'loss', 'acc', 'lr'])\n",
      "\n",
      "    if config[\"cuda_devices\"] is not None:\n",
      "        gpu_list = list(range(0, 2))\n",
      "        model = nn.DataParallel(model, gpu_list).cuda()  # multi-gpu training\n",
      "        loss_function = loss_function.cuda() \n",
      "#         model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
      "#         loss_function = loss_function.to(device=device)\n",
      "        \n",
      "    if not config[\"overwrite\"] and config[\"saved_model_file\"] is not None:\n",
      "        if not os.path.exists(config[\"saved_model_file\"]):\n",
      "            raise Exception(\"Invalid model path!\")\n",
      "        model, start_epoch, optimizer = load_old_model(model, optimizer, saved_model_path=config[\"saved_model_file\"])    \n",
      "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=config[\"lr_decay\"],patience=config[\"patience\"])\n",
      "    \n",
      "    print(\"training on label:{}\".format(config[\"labels\"]))\n",
      "    max_val_acc = 0.\n",
      "    for i in range(start_epoch,config[\"epochs\"]):\n",
      "        train_epoch(epoch=i, \n",
      "                    data_set=training_data, \n",
      "                    model=model,\n",
      "                    criterion=loss_function, \n",
      "                    optimizer=optimizer, \n",
      "                    opt=config, \n",
      "                    logger=train_logger) \n",
      "        \n",
      "        val_loss, val_acc = val_epoch(epoch=i, \n",
      "                  data_set=validation_data, \n",
      "                  model=model, \n",
      "                  criterion=loss_function, \n",
      "                  opt=config,\n",
      "                  optimizer=optimizer, \n",
      "                  logger=train_logger)\n",
      "        scheduler.step(val_loss)\n",
      "        if config[\"checkpoint\"] and val_acc > max_val_acc:\n",
      "            max_val_acc = val_acc\n",
      "            save_dir = os.path.join(config[\"result_path\"], config[\"model_file\"].split(\"/\")[-1].split(\".h5\")[0])\n",
      "            if not os.path.exists(save_dir):\n",
      "                os.makedirs(save_dir)\n",
      "            save_states_path = os.path.join(save_dir,'epoch_{0}_val_loss_{1:.4f}_acc_{2:.4f}.pth'.format(i, val_loss, val_acc))\n",
      "            states = {\n",
      "                'epoch': i + 1,\n",
      "                'state_dict': model.state_dict(),\n",
      "                'optimizer': optimizer.state_dict(),\n",
      "            }\n",
      "            torch.save(states, save_states_path)\n",
      "            save_model_path = os.path.join(save_dir, \"best_model_file.pth\")\n",
      "            if os.path.exists(save_model_path):\n",
      "                os.system(\"rm \"+save_model_path)\n",
      "            torch.save(model, save_model_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "init model with input shape (2, 1, 128, 128, 128)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data generating\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training on label:(1,)\n",
        "train at epoch 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "  0%|          | 0/49 [00:00<?, ?it/s]"
       ]
      },
      {
       "ename": "RuntimeError",
       "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.90 GiB total capacity; 4.23 GiB already allocated; 368.88 MiB free; 3.19 MiB cached)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-6-4e1864091cd5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     logger=train_logger) \n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         val_loss, val_acc = val_epoch(epoch=i, \n",
        "\u001b[0;32m~/BraTS2018_NvNet/train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, data_set, model, criterion, optimizer, opt, logger)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VAE_enable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36m_worker\u001b[0;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/BraTS2018_NvNet/nvnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mout_de2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_up2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_en3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_en2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mout_de1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_up1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_de2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_en1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mout_de0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_block0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_up0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_de1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_en0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mout_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_de0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/BraTS2018_NvNet/nvnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skipx)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskipx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.90 GiB total capacity; 4.23 GiB already allocated; 368.88 MiB free; 3.19 MiB cached)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
